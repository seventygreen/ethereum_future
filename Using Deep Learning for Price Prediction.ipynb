{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Deep Learning for Price Prediction\n",
    "\n",
    "This notebook Recurrent Neural Networks (RNN) for price prediction of securities and crypto currencies; it is based on the notebook [A Deep Learning Approach to Predicting Cryptocurrency Prices](https://github.com/llSourcell/ethereum_future).\n",
    "\n",
    "![alt text](https://dashee87.github.io/images/bitcoin_ether_training_test.png \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "from keras.models import Sequential\n",
    "\n",
    "# mapping metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# logging\n",
    "import time\n",
    "\n",
    "# matrix math\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data processing\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](http://2.bp.blogspot.com/-wuinSTn-X4A/UwHmmceDQqI/AAAAAAAAJFo/5EjPg-LpAJc/s1600/Sivakumar_Vellingiri_Normal_Forms_Poster.Jpeg \"Logo Title Text 1\")\n",
    "\n",
    "# Step 1 - Data Processing\n",
    "\n",
    "- Read trading data from .csv file. The notebook assumes for the price to be in the first column (column 0), followed by an arbitrary number of features (of type float).\n",
    "- Transform data format from \"num days x num features\" into \"(num days - window size) x num days per sample x num features\".\n",
    "- Normalize data by dividing each value in the window by the first value of the window and then subtracting one, e.g. [4,3,2] into [0, -0.25, -0.5]; keep the unnormalized bases to compare the model's predictions of prices with the true prices.\n",
    "- Split the data into training the model and test data. \n",
    "- A list of the prices before each day Y_test is drawn from will be compiled in order to generate statistics about the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name, sequence_length):\n",
    "    \"\"\"\n",
    "    Loads historic trading from .csv file.\n",
    "    \n",
    "    Arguments:\n",
    "    file_name -- string: location of .csv file.\n",
    "    sequence_length -- integer: how many days should be looked at in a row.\n",
    "    \n",
    "    Returns:\n",
    "    X_train -- tensor (shape = train_lines, sequence_length-1, num_features): training input.\n",
    "    Y_train -- tensor (shape = train_lines,): training output.\n",
    "    X_test -- tensor (shape = test_lines, sequence_length-1, num_features): test input.\n",
    "    Y_test -- tensor (shape = test_lines,): test output.\n",
    "    Y_daybefore -- tensor (shape = test_lines,): prices from previous day (to compare Y_test value). \n",
    "    unnormalized_bases -- tensor (shape = test_lines,): true, unnormalized prices.\n",
    "    window_size -- integer: sequence_length-1.\n",
    "    \"\"\"\n",
    "    \n",
    "    # parameters for this function\n",
    "    training_to_test_ratio = .8 # 80% training, 20% test data\n",
    "    price_col_idx = 0 # price is column[0]\n",
    "    \n",
    "    # read the data file and convert to list\n",
    "    data = pd.read_csv(file_name, dtype = float).values.tolist()\n",
    "    #data = data[:5000] # limit input for testing\n",
    "    \n",
    "    # convert the data to a 3D array (a x b x c) \n",
    "    # where: a is the number of days, b is the sequence length, and c is the number of features in the data file.\n",
    "    result = []\n",
    "    for index in range(len(data) - sequence_length):\n",
    "        result.append(data[index: index + sequence_length])\n",
    "    \n",
    "    # normalize price (target variable for optimization)\n",
    "    # for each sequence, divide each  price (col[0]) in the sequence by the first price, and subtract 1.\n",
    "    d0 = np.array(result)\n",
    "    dr = np.zeros_like(d0)\n",
    "    dr[:,:,1:] = d0[:,:,1:]\n",
    "    dr[:,1:,0:1] = d0[:,1:,0:1] / d0[:,0:1,0:1] - 1.0\n",
    "\n",
    "    # calculate cut between training and test data\n",
    "    split_line = round(d0.shape[0] * training_to_test_ratio)\n",
    "\n",
    "    # prepare the training data\n",
    "    training_data = dr[:split_line]\n",
    "    np.random.shuffle(training_data)\n",
    "\n",
    "    # keep the original, unnormalized prices for Y_test\n",
    "    # [for labeling prices]\n",
    "    unnormalized_bases = d0[split_line:,0,price_col_idx]\n",
    "    \n",
    "    # get training data\n",
    "    X_train = training_data[:, :-1]\n",
    "    Y_train = training_data[:, -1]\n",
    "    Y_train = Y_train[:, price_col_idx]\n",
    "    \n",
    "    # get test data\n",
    "    X_test = dr[split_line:, :-1]\n",
    "    Y_test = dr[split_line:, -1, :]\n",
    "    Y_test = Y_test[:, price_col_idx]\n",
    "\n",
    "    # day before Y_test's price\n",
    "    Y_daybefore = dr[split_line:, -2, :]\n",
    "    Y_daybefore = Y_daybefore[:, price_col_idx]\n",
    "    \n",
    "    # adjust window_size: last value in the sequence is reserved as Y-value\n",
    "    window_size = sequence_length - 1\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test, Y_daybefore, unnormalized_bases, window_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Building the Model\n",
    "\n",
    "- We'll use a 3layer RNN with  20% dropout at each layer to reduce overfitting to the training data. \n",
    "- This model will have 515,579 trainable parameters throughout all of its layers. \n",
    "- The model uses the AdamOptimizer as its optimization function.\n",
    "- The loss function used in this model is mean squared error. \n",
    "- A linear activation function f(x) = x is used in this model to determine the output of each neuron in the model.\n",
    "- The model will use Keras' Sequential model with Bidirectional LSTM layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/rnn.jpg \"Logo Title Text 1\")\n",
    "![alt text](https://docs.microsoft.com/en-us/azure/machine-learning/preview/media/scenario-tdsp-biomedical-recognition/lstm-cell.png \"Logo Title Text 1\")\n",
    "![alt text](http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/bidirectional-rnn.png \"Logo Title Text 1\")\n",
    "![alt text](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/05/Comparison-of-Adam-to-Other-Optimization-Algorithms-Training-a-Multilayer-Perceptron.png \"Logo Title Text 1\")\n",
    "\n",
    "\n",
    "Bidirectional RNNs are based on the idea that the output at time t may not only depend on the previous elements in the sequence, but also future elements. For example, to predict a missing word in a sequence you want to look at both the left and the right context. Bidirectional RNNs are quite simple. They are just two RNNs stacked on top of each other. The output is then computed based on the hidden state of both RNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(window_size, dropout_value, activation_function, loss_function, optimizer):\n",
    "    \"\"\"\n",
    "    Initializes and creates a model.\n",
    "    \n",
    "    Arguments:\n",
    "    window_size -- integer: number of X_values (days) the model looks at at once.\n",
    "    dropout_value -- decimal: dropout to be incorporated at each level (in this case .2).\n",
    "    activation_function -- string: activation function (in this case \"linear\").\n",
    "    loss_function -- string: loss function (in the case \"mean squared error\").\n",
    "    optimizer -- string: optimizer (in the case \"it is \"adam\").\n",
    "    \n",
    "    Returns:\n",
    "    model -- 3-layer RNN as per configuration.\n",
    "    \"\"\"\n",
    "    # create a Sequential model using Keras\n",
    "    model = Sequential()\n",
    "\n",
    "    # first recurrent layer with dropout\n",
    "    model.add(Bidirectional(LSTM(window_size, return_sequences=True), input_shape=(window_size, X_train.shape[-1]),))\n",
    "    model.add(Dropout(dropout_value))\n",
    "\n",
    "    # second recurrent layer with dropout\n",
    "    model.add(Bidirectional(LSTM((window_size*2), return_sequences=True)))\n",
    "    model.add(Dropout(dropout_value))\n",
    "\n",
    "    # third recurrent layer\n",
    "    model.add(Bidirectional(LSTM(window_size, return_sequences=False)))\n",
    "\n",
    "    # output layer (returns the predicted value)\n",
    "    model.add(Dense(units=1))\n",
    "    \n",
    "    # set activation function\n",
    "    model.add(Activation(activation_function))\n",
    "\n",
    "    # set loss function and optimizer\n",
    "    model.compile(loss=loss_function, optimizer=optimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Training the Model\n",
    "\n",
    "- The model will be fitted to the training dat with a batch_size of 1024. \n",
    "- Additionally, 100 epochs will be performed to give the model time to adjust its weights and biases to fit the training data.\n",
    "- 5% of the training data will be used as the validation set.  \n",
    "- The model will train by minimizing the loss (mean squared error) of its training data.\n",
    "- The validation set is useful when attempting to identify signs of overfitting. \n",
    "- If the validation loss begins to consistently and rapidly increase, the model has overfitted to the training data, and changes should be made to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fit_model(model, X_train, Y_train, batch_num, num_epoch, val_split):\n",
    "    \"\"\"\n",
    "    Fits the model to the training data.\n",
    "    \n",
    "    Arguments:\n",
    "    model -- e.g. 3-layer Recurrent Neural Network.\n",
    "    X_train -- tensor (shape = lines * .8, 49, 35): X values of the training data.\n",
    "    Y_train -- tensor of shape (lines * .8,): Y values of the training data.\n",
    "    batch_num -- integer: batch size (e.g. 1,024).\n",
    "    num_epoch -- integer: number of epochs to be run (e.g. 100).\n",
    "    val_split -- decimal: proportion of training data to be used as validation data.\n",
    "    \n",
    "    Returns:\n",
    "    model -- fitted 3-layer Recurrent Neural Network.\n",
    "    training_time -- integer: amount of time (in seconds) spent to train the model.\n",
    "    \"\"\"\n",
    "    # record the time the model starts training\n",
    "    start = time.time()\n",
    "\n",
    "    # train the model on X_train and Y_train\n",
    "    model.fit(X_train, Y_train, batch_size=batch_num, epochs=num_epoch, validation_split=val_split)\n",
    "\n",
    "    # get the time it took to train the model (in seconds)\n",
    "    training_time = int(math.floor(time.time() - start))\n",
    "    \n",
    "    return model, training_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Testing the Model\n",
    "\n",
    "- The models given x values of testing data & will predict normalized prices (y_predict)\n",
    "- Then, both the predicted values and the real values will be unnormalized and stored in separate arrays. \n",
    "- The values are unnormalized by looping through the predicted and true values. \n",
    "- 1 is added to each value, and then the result is multiplied by a corresponding number in the unnormalized_bases array. \n",
    "- In other words, the unnormalization processs is the exact reverse of the normalization process\n",
    "- Finally, a plot is created of the unnormalized real values and the unnormalized predicted values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_model(model, X_test, Y_test, unnormalized_bases):\n",
    "    \"\"\"\n",
    "    Test the model on the testing data\n",
    "    \n",
    "    Arguments:\n",
    "    model -- fitted 3-layer Recurrent Neural Network.\n",
    "    X_test -- tensor (shape = test_lines, sequence_length-1, num_of_features): X values of the testing data.\n",
    "    Y_test -- tensor (shape = lines * .2,): Y  values of the testing data.\n",
    "    unnormalized_bases -- tensor (shape = lines * .2,): unnormalized data points.\n",
    "    \n",
    "    Returns:\n",
    "    y_predict -- tensor (shape = lines * .2,): normalized values that the model predicts based on X_test.\n",
    "    real_y_test -- tensor (shape = lines * .2,): actual prices of bitcoin throughout the testing period.\n",
    "    real_y_predict -- tensor (shape = lines * .2,): model's predicted prices.\n",
    "    fig -- A branch of the graph of predicted prices vs. real prices.\n",
    "    \"\"\"\n",
    "    # test the model on X_test\n",
    "    y_predict = model.predict(X_test)\n",
    "\n",
    "    # create empty 2D arrays to store unnormalized values\n",
    "    real_y_test = np.zeros_like(Y_test)\n",
    "    real_y_predict = np.zeros_like(y_predict)\n",
    "\n",
    "    # fill the 2D arrays with the real value and the predicted value by reversing the normalization process\n",
    "    for i in range(Y_test.shape[0]):\n",
    "        y = Y_test[i]\n",
    "        predict = y_predict[i]\n",
    "        real_y_test[i] = (y+1.0)*unnormalized_bases[i]\n",
    "        real_y_predict[i] = (predict+1.0)*unnormalized_bases[i]\n",
    "        \n",
    "    # plot of the predicted prices versus the real prices\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(\"Price Over Time\")\n",
    "    plt.plot(real_y_predict, color = 'green', label = 'Predicted Price')\n",
    "    plt.plot(real_y_test, color = 'red', label = 'Real Price')\n",
    "    ax.set_ylabel(\"Price\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.legend()\n",
    "    \n",
    "    return y_predict, real_y_test, real_y_predict, fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 - Evaluating Change in Price\n",
    "\n",
    "- Lets plot the model's predicted change in price each day against the real change in price daily\n",
    "- The percent increases of the predicted values and the real values are calculated by subtracting the value from the day before from the predicted/real value then dividing the result by 1+the value from the day before. \n",
    "- The predicted change in price is stored in delta_predict, while the real change in price is stored in delta_real.\n",
    "- These two tensors are then graphed together to visualize the difference between predicted and real change in price for bitcoin throughout the testing period. \n",
    "- The plot will represent the percent change in bitcoin price each day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_change(Y_daybefore, Y_test, y_predict):\n",
    "    \"\"\"\n",
    "    Calculate the percent change between each value and the day before.\n",
    "    \n",
    "    Arguments:\n",
    "    Y_daybefore -- A tensor of shape (267,) that represents the prices of each day before each price in Y_test\n",
    "    Y_test -- A tensor of shape (267,) that represents the normalized y values of the testing data\n",
    "    y_predict -- A tensor of shape (267,) that represents the normalized y values of the model's predictions\n",
    "    \n",
    "    Returns:\n",
    "    Y_daybefore -- A tensor of shape (267, 1) that represents the prices of each day before each price in Y_test\n",
    "    Y_test -- A tensor of shape (267, 1) that represents the normalized y values of the testing data\n",
    "    delta_predict -- A tensor of shape (267, 1) that represents the difference between predicted and day before values\n",
    "    delta_real -- A tensor of shape (267, 1) that represents the difference between real and day before values\n",
    "    fig -- A plot representing percent change in bitcoin price per day,\n",
    "    \"\"\"\n",
    "    #Reshaping Y_daybefore and Y_test\n",
    "    Y_daybefore = np.reshape(Y_daybefore, (-1, 1))\n",
    "    Y_test = np.reshape(Y_test, (-1, 1))\n",
    "\n",
    "    #The difference between each predicted value and the value from the day before\n",
    "    delta_predict = (y_predict - Y_daybefore) / (1+Y_daybefore)\n",
    "\n",
    "    #The difference between each true value and the value from the day before\n",
    "    delta_real = (Y_test - Y_daybefore) / (1+Y_daybefore)\n",
    "\n",
    "    #Plotting the predicted percent change versus the real percent change\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(\"Percent Change in Bitcoin Price Per Day\")\n",
    "    plt.plot(delta_predict, color='green', label = 'Predicted Percent Change')\n",
    "    plt.plot(delta_real, color='red', label = 'Real Percent Change')\n",
    "    plt.ylabel(\"Percent Change\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return Y_daybefore, Y_test, delta_predict, delta_real, fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 - Process the Percent Change in Price\n",
    "\n",
    "- The percent change in price will be processsed such that an increase in price is represented by a 1, and a decrease/no change is represented by a 0. These binary values will be stored in arrays delta_predict_1_0 and delta_real_1_0. \n",
    "\n",
    "- This will be done by looping through the values of the real and predicted percent change arrays. If a value is greater than 0, a 1 is stored in a new array. Otherwise, a 0 is stored in the new array.\n",
    "\n",
    "- This process is very useful to understand how well the model did, and can be used to gather statistics about the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def binary_price(delta_predict, delta_real):\n",
    "    \"\"\"\n",
    "    Converts percent change to a binary 1 or 0, where 1 is an increase and 0 is a decrease/no change\n",
    "    \n",
    "    Arguments:\n",
    "    delta_predict -- A tensor of shape (267, 1) that represents the predicted percent change in price\n",
    "    delta_real -- A tensor of shape (267, 1) that represents the real percent change in price\n",
    "    \n",
    "    Returns:\n",
    "    delta_predict_1_0 -- A tensor of shape (267, 1) that represents the binary version of delta_predict\n",
    "    delta_real_1_0 -- A tensor of shape (267, 1) that represents the binary version of delta_real\n",
    "    \"\"\"\n",
    "    #Empty arrays where a 1 represents an increase in price and a 0 represents a decrease in price\n",
    "    delta_predict_1_0 = np.empty(delta_predict.shape)\n",
    "    delta_real_1_0 = np.empty(delta_real.shape)\n",
    "\n",
    "    #If the change in price is greater than zero, store it as a 1\n",
    "    #If the change in price is less than zero, store it as a 0\n",
    "    for i in range(delta_predict.shape[0]):\n",
    "        if delta_predict[i][0] > 0:\n",
    "            delta_predict_1_0[i][0] = 1\n",
    "        else:\n",
    "            delta_predict_1_0[i][0] = 0\n",
    "    for i in range(delta_real.shape[0]):\n",
    "        if delta_real[i][0] > 0:\n",
    "            delta_real_1_0[i][0] = 1\n",
    "        else:\n",
    "            delta_real_1_0[i][0] = 0    \n",
    "\n",
    "    return delta_predict_1_0, delta_real_1_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Comparing Predictions and Real Data\n",
    "\n",
    "The binary categories computed in the previous cell is now used to compare predicted and real data. It will be used to find the number of:\n",
    "- True positives\n",
    "- False positives\n",
    "- True negatives\n",
    "- False negatives\n",
    "These can then be used to further calculate statistics of the model's performance. \n",
    "\n",
    "This will be done by looping through both binary arrays at once and getting the corresponding values. If the real value is a 1 and the predicted value is a 1, that index will be counted as a true positive. If the real value is a 1 and the predicted value is a 0, that index will be counted as a false negative. If the real value is a 0 and the predicted value is a 0, that index will be counted as a true negative. If the real value is a 0 and the predicted value is a 1, that index will be counted as a false positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_positives_negatives(delta_predict_1_0, delta_real_1_0):\n",
    "    \"\"\"\n",
    "    Finding the number of false positives, false negatives, true posiStives, true negatives\n",
    "    \n",
    "    Arguments: \n",
    "    delta_predict_1_0 -- A tensor of shape (267, 1) that represents the binary version of delta_predict\n",
    "    delta_real_1_0 -- A tensor of shape (267, 1) that represents the binary version of delta_real\n",
    "    \n",
    "    Returns:\n",
    "    true_pos -- An integer that represents the number of true positives achieved by the model\n",
    "    false_pos -- An integer that represents the number of false positives achieved by the model\n",
    "    true_neg -- An integer that represents the number of true negatives achieved by the model\n",
    "    false_neg -- An integer that represents the number of false negatives achieved by the model\n",
    "    \"\"\"\n",
    "    #Finding the number of false positive/negatives and true positives/negatives\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    true_neg = 0\n",
    "    false_neg = 0\n",
    "    for i in range(delta_real_1_0.shape[0]):\n",
    "        real = delta_real_1_0[i][0]\n",
    "        predicted = delta_predict_1_0[i][0]\n",
    "        if real == 1:\n",
    "            if predicted == 1:\n",
    "                true_pos += 1\n",
    "            else:\n",
    "                false_neg += 1\n",
    "        elif real == 0:\n",
    "            if predicted == 0:\n",
    "                true_neg += 1\n",
    "            else:\n",
    "                false_pos += 1\n",
    "    return true_pos, false_pos, true_neg, false_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 - Calculating Statistics\n",
    "\n",
    "![alt text](https://www.researchgate.net/profile/Alexandros_Karatzoglou/publication/221515860/figure/fig1/AS:339586132791298@1457975051470/Figure-1-Mean-Squared-Error-formula-used-to-evaluate-the-user-model.ppm \"Logo Title Text 1\")\n",
    "\n",
    "![alt text](https://image.slidesharecdn.com/qconrio-machinelearningforeveryone-150826200704-lva1-app6892/95/qcon-rio-machine-learning-for-everyone-51-638.jpg?cb=1440698161 \"Logo Title Text 1\")\n",
    "\n",
    "\n",
    "Putting everything together and getting statistics about the model. Statistics being calculated include:\n",
    "- Precision: How often the model gets a true positive compared to how often it returns a positive\n",
    "- Recall: How often the model gets a true positive compared to how often it should have gotten a positive\n",
    "- F1 Score: The weighted average of recall and precision\n",
    "- Mean Squared Error: The average of the squares of the differences between predicted and real values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(true_pos, false_pos, true_neg, false_neg, y_predict, Y_test):\n",
    "    \"\"\"\n",
    "    Calculate various statistics to assess performance\n",
    "    \n",
    "    Arguments:\n",
    "    true_pos -- An integer that represents the number of true positives achieved by the model\n",
    "    false_pos -- An integer that represents the number of false positives achieved by the model\n",
    "    true_neg -- An integer that represents the number of true negatives achieved by the model\n",
    "    false_neg -- An integer that represents the number of false negatives achieved by the model\n",
    "    Y_test -- A tensor of shape (267, 1) that represents the normalized y values of the testing data\n",
    "    y_predict -- A tensor of shape (267, 1) that represents the normalized y values of the model's predictions\n",
    "    \n",
    "    Returns:\n",
    "    precision -- How often the model gets a true positive compared to how often it returns a positive\n",
    "    recall -- How often the model gets a true positive compared to how often is hould have gotten a positive\n",
    "    F1 -- The weighted average of recall and precision\n",
    "    Mean Squared Error -- The average of the squares of the differences between predicted and real values\n",
    "    \"\"\"\n",
    "    precision = float(true_pos) / (true_pos + false_pos)\n",
    "    recall = float(true_pos) / (true_pos + false_neg)\n",
    "    F1 = float(2 * precision * recall) / (precision + recall)\n",
    "    #Get Mean Squared Error\n",
    "    MSE = mean_squared_error(y_predict.flatten(), Y_test.flatten())\n",
    "\n",
    "    return precision, recall, F1, MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 - Putting It All Together\n",
    "\n",
    "Applying all the methods defined above and analyzing results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"data/kraken-XXBTZUSD-test.csv\"\n",
    "# file_name = \"data/coinbase-ETHxUSD-test-10000.csv\"\n",
    "sequence_length = 50\n",
    "\n",
    "X_train, Y_train, X_test, Y_test, Y_daybefore, unnormalized_bases, window_size = load_data(file_name, sequence_length)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "print(Y_daybefore.shape)\n",
    "print(unnormalized_bases.shape)\n",
    "print(window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initialize_model(window_size, 0.2, 'linear', 'mse', 'adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, training_time = fit_model(model, X_train, Y_train, 1024, 50, .05)\n",
    "print(\"Training time\", training_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict, real_y_test, real_y_predict, fig1 = test_model(model, X_test, Y_test, unnormalized_bases)\n",
    "\n",
    "# plot the errors\n",
    "plt.show(fig1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Plotting Percent Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_daybefore, Y_test, delta_predict, delta_real, fig2 = price_change(Y_daybefore, Y_test, y_predict)\n",
    "\n",
    "#Show the plot\n",
    "plt.show(fig2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Binary Version of Percent Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_predict_1_0, delta_real_1_0 = binary_price(delta_predict, delta_real)\n",
    "\n",
    "print(delta_predict_1_0.shape)\n",
    "print(delta_real_1_0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Predictions and True Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos, false_pos, true_neg, false_neg = find_positives_negatives(delta_predict_1_0, delta_real_1_0)\n",
    "print(\"True positives:\", true_pos)\n",
    "print(\"False positives:\", false_pos)\n",
    "print(\"True negatives:\", true_neg)\n",
    "print(\"False negatives:\", false_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "precision, recall, F1, MSE = calculate_statistics(true_pos, false_pos, true_neg, false_neg, y_predict, Y_test)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 score:\", F1)\n",
    "print(\"Mean Squared Error:\", MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Youtube video is here:\n",
    "\n",
    "- https://www.youtube.com/watch?v=G5Mx7yYdEhE\n",
    " \n",
    "All of the mentioned fields can be retrieved from (or computed using data from), a bevy of free data sources.\n",
    "\n",
    "- https://www.quandl.com/data/BCHAIN-Blockchain\n",
    "- https://www.kaggle.com/mczielinski/bitcoin-historical-data\n",
    "- https://blockchain.info/stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix - Getting Historical Trading Data from Kraken\n",
    "\n",
    "## Kraken API\n",
    "\n",
    "For this variant of the notebook, we will use price data from Kraken, which is readily available through Kraken's APIs. In later versions, we will add data from other exchanges and add additional columns. Se below for the complete list of the columns used in the original version.\n",
    "\n",
    "For a more complete discussion of Kraken APIs, schemas, and examples, see https://www.kraken.com/help/api#example-api-code-python3.\n",
    "\n",
    "Get recent trades\n",
    "URL: https://api.kraken.com/0/public/Trades\n",
    "\n",
    "Input:\n",
    "\n",
    "```\n",
    "pair = asset pair to get trade data for\n",
    "since = return trade data since given id (optional.  exclusive)\n",
    "```\n",
    "\n",
    "Result: array of pair name and recent trade data\n",
    "\n",
    "```\n",
    "<pair_name> = pair name\n",
    "    array of array entries(<price>, <volume>, <time>, <buy/sell>, <market/limit>, <miscellaneous>)\n",
    "last = id to be used as since when polling for new trade data\n",
    "```\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"error\":[],\n",
    "    \"result\":{\n",
    "        \"XXBTZEUR\":[\n",
    "            [\"97.00000\",\"1.00000000\",1378856831.546,\"s\",\"m\",\"\"],\n",
    "            [\"99.90000\",\"0.10000000\",1378859634.7626,\"b\",\"m\",\"\"]\n",
    "        ],\n",
    "        \"last\":\"1383839436659595694\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "## API Documentation\n",
    "- [Python 3 examples for the Kraken API](https://www.kraken.com/help/api#example-api-code-python3)\n",
    "- [Public trades for XBT in EUR](https://api.kraken.com/0/public/Trades?pair=XXBTZEUR&since=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Client\n",
    "Function to read historic trade data from Kraken API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import urllib.request\n",
    "import json\n",
    "import time\n",
    "\n",
    "# parameters\n",
    "pair = 'XXBTZUSD'\n",
    "outfile = 'data/kraken-' + pair + '-test.csv'\n",
    "\n",
    "# constants\n",
    "base_url_trades = 'https://api.kraken.com/0/public/Trades?pair='\n",
    "column_names = ['price','volume','time','buysell','marketlimit','misc']\n",
    "\n",
    "# retrieve data from Kraken\n",
    "def get_trade_data_Kraken(pair, start = None, end = None):\n",
    "    url_trades = base_url_trades + pair\n",
    "    if start:\n",
    "        url_trades = url_trades + \"&since=\" + start\n",
    "    with urllib.request.urlopen(url_trades) as response:\n",
    "        t = response.read().decode()\n",
    "        j = json.loads(s)\n",
    "        \n",
    "        # handle errors\n",
    "        if j[\"error\"]:\n",
    "            return\n",
    "            \n",
    "        # marker for next query\n",
    "        last = float(j[\"result\"][\"last\"]) / 1000000000.0\n",
    "\n",
    "        # trade data\n",
    "        df = pd.DataFrame(j[\"result\"][pair],columns=column_names)\n",
    "        df['marketlimit'] = df['marketlimit'].map({'m': 0, 'l': 1})\n",
    "        df['buysell'] = df['buysell'].map({'b': 0, 's': 1})\n",
    "        del df['misc']        \n",
    "        \n",
    "        return last, df\n",
    "\n",
    "# test using BTC vs USD\n",
    "last, df = get_trade_data_Kraken(pair)\n",
    "print(last)\n",
    "print(df.shape)\n",
    "print(df)\n",
    "\n",
    "# write to .csv file\n",
    "df.to_csv(outfile, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix - Cryptocurrency Data from Coinbase\n",
    "\n",
    "To be filled in.\n",
    "\n",
    "type,trade_id,maker_order_id,taker_order_id,side,size,price,product_id,sequence,time,received,open,changed,done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix - Original input schema\n",
    "\n",
    "The data columns and their definitions from [the original notebook](https://github.com/llSourcell/ethereum_future) for predicting cryptocurrency prices are as follows:\n",
    "\n",
    "- Annual Hash Growth: Growth in the total network computations over the past 365 days\n",
    "- Block Height: The total number of blocks in the blockchain\n",
    "- Block Interval: Average amount of time between blocks\n",
    "- Block Size: The storage size of each block (i.e. megabytes)\n",
    "- BlockChain Size: The storage size of the blockchain (i.e. gigabytes)\n",
    "- Daily Blocks: Number of blocks found each day\n",
    "- Chain Value Density: The value of bitcoin's blockchain, in terms of dollars per megabyte\n",
    "- Daily Transactions: The number of transactions included in the blockchain per day\n",
    "- Difficulty: The minimum proof-of-work threshold required for a bitcoin miner to mine a block\n",
    "- Fee Percentage: Average fee paid as a percentage of transaction volume\n",
    "- Fee Rate: Average fee paid per transaction\n",
    "- Two-Week Hash Growth: Growth in the total network computations over the past 14 days\n",
    "- Hash Rate: The number of block solutions computed per second by all miners\n",
    "- Market Capitalization: The market value of all bitcoin in circulation\n",
    "- Metcalfe's Law - TX: A variant of Metcalfe's Law in which price is divided by n log n number of daily transactions\n",
    "- Metcalfe's Law - UTXO: A variant of Metcalfe's Law in which price is divided by n log n number of unspent transaction outputs\n",
    "- Miner Revenue Value: The amount of dollars earned by the mining network\n",
    "- Miner Revenue: The amount of bitcoin earned by the mining network, in the form of block rewards and transaction fees\n",
    "- Money Supply: The amount of bitcoin in circulation\n",
    "- Output Value: The dollar value of all outputs sent over the network\n",
    "- Output Volume: The amount of Bitcoin sent over the network\n",
    "- Bitcoin Price: The amount of dollars a single bitcoin is worth\n",
    "- Quarterly Hash Growth: Growth in the total network computations in the past 90 days\n",
    "- Total Transactions: The running total number of transactions processed by the Bitcoin network\n",
    "- Transaction Amount: The average amount of bitcoin moved per transaction\n",
    "- Fees Value: The dollar value of mining fees\n",
    "- Transaction Fees: The amount of bitcoin paid to miners in fees\n",
    "- Transaction Size: The average data size of a transaction\n",
    "- Transaction Value: The average dollar value moved in each transaction\n",
    "- Transactions per Block: The number of transactions in each block\n",
    "- Average UTXO Amount: The average amount of bitcoin contained in each unspent transaction output\n",
    "- UTXO Growth: The net number of unspent transaction outputs created\n",
    "- UTXO Set Size: The total number of unspent transaction outputs\n",
    "- Average UTXO Value: The average dollar value of each uspent transaction output\n",
    "- Velocity - Daily: The proportion of the money supply transacted each day\n",
    "- Velocity - Quarterly: The proportion of the money supply transacted each day, computed on a rolling-quarter basis\n",
    "- Velocity of Money: How many times the money supply changes hands in a given year"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
